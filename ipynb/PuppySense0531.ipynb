{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14ncW2slHZx0"
      },
      "source": [
        "# PuppySense\n",
        "\n",
        "인공지능응용 프로젝트\n",
        "\n",
        "모델학습 (colab 환경설정, 전이 학습 설정 진행)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srtlgyO67R6l"
      },
      "source": [
        "## 1. Colab 환경설정 (GPU + 라이브러리 설치)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL17skCZG1Le",
        "outputId": "e4018e4a-6f88-4cc7-e3fc-f5aafeac96c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (2.19.0)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (3.10.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (75.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (2.1.3)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: efficientnet in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (1.1.1)\n",
            "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from efficientnet) (1.0.8)\n",
            "Requirement already satisfied: scikit-image in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from efficientnet) (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (2.1.3)\n",
            "Requirement already satisfied: h5py in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.13.0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from scikit-image->efficientnet) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from scikit-image->efficientnet) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from scikit-image->efficientnet) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from scikit-image->efficientnet) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from scikit-image->efficientnet) (2025.5.26)\n",
            "Requirement already satisfied: packaging>=21 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from scikit-image->efficientnet) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from scikit-image->efficientnet) (0.4)\n",
            "Requirement already satisfied: pandas in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (2.1.3)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (4.11.0.86)\n",
            "Requirement already satisfied: tensorflow in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (2.19.0)\n",
            "Requirement already satisfied: kagglehub in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (0.3.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (75.8.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\oculo\\desktop\\test\\artificialin\\.conda\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow opencv-python matplotlib\n",
        "!pip install efficientnet\n",
        "!pip install pandas numpy opencv-python tensorflow kagglehub\n",
        "!pip install scikit-learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA0COst99L6j"
      },
      "source": [
        "# 2. 데이터 전처리하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qARcpW7i-UiJ"
      },
      "source": [
        "## 2.1 kaggle 데이터 다운하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kp5M_tdU9UpI",
        "outputId": "0545b373-06d3-48d4-8ec2-563eaf23e8b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "실제 다운로드된 경로: C:\\Users\\oculo\\.cache\\kagglehub\\datasets\\danielshanbalico\\dog-emotion\\versions\\1\n",
            "해당 경로 내 파일/폴더: ['Dog Emotion']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import kagglehub\n",
        "\n",
        "# 1. kagglehub로 실제 경로 다운로드\n",
        "path = kagglehub.dataset_download(\"danielshanbalico/dog-emotion\")\n",
        "data_dir = os.path.join(path, 'Dog Emotion')\n",
        "print(\"실제 다운로드된 경로:\", path)\n",
        "print(\"해당 경로 내 파일/폴더:\", os.listdir(path))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryn6M_zHaay5"
      },
      "source": [
        "## 2.2 테이터 로드\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3mlSDaebA8U",
        "outputId": "a5388653-7c53-4c24-9052-fb67fe0997b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "클래스 목록: ['angry', 'happy', 'relaxed', 'sad']\n"
          ]
        }
      ],
      "source": [
        "# 2. labels.csv 경로\n",
        "labels_csv_path = os.path.join(data_dir, 'labels.csv')\n",
        "labels_df = pd.read_csv(labels_csv_path)\n",
        "\n",
        "# 3. 감정 레이블 폴더 이름 불러오기\n",
        "class_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
        "print(f'클래스 목록: {class_names}')\n",
        "\n",
        "# 4. 레이블 매핑\n",
        "label_map = {name: idx for idx, name in enumerate(class_names)}\n",
        "\n",
        "# 5. 이미지 로딩 함수\n",
        "def load_and_preprocess_img(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        print(f\"이미지 파일을 불러올 수 없습니다: {img_path}\")\n",
        "        return None\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (600, 600))\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "# 6. 이미지 및 레이블 로딩\n",
        "images, labels = [], []\n",
        "for _, row in labels_df.iterrows():\n",
        "    img_path = os.path.join(data_dir, row['label'], row['filename'])\n",
        "    img = load_and_preprocess_img(img_path)\n",
        "    if img is not None:\n",
        "        images.append(img)\n",
        "        labels.append(label_map[row['label']])\n",
        "\n",
        "# 7. 배열 및 one-hot 인코딩\n",
        "images = np.array(images)\n",
        "labels = tf.keras.utils.to_categorical(labels, num_classes=len(class_names))\n",
        "\n",
        "# 8. 확인\n",
        "print(f'이미지 개수: {images.shape[0]}, 라벨 개수: {labels.shape[0]}')\n",
        "print(f'라벨 예시 (one-hot):\\n{labels[:5]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHzxF4C5i0gd"
      },
      "source": [
        "# 3. test, valid, train set 나누기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pZvNwgFOi-4X"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1) train+val / test 분리 (10%를 test로 분리)\n",
        "train_val_images, test_images, train_val_labels, test_labels = train_test_split(\n",
        "    images, labels, test_size=0.1, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "# 2) train / val 분리 (train_val 중 10%를 validation으로 분리)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_val_images, train_val_labels, test_size=0.1, random_state=42, stratify=train_val_labels\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sz-k63E7Y7_"
      },
      "source": [
        "# 4. 전이 학습 모델 구성 (EfficientNetB0 사용)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6umalnALggH"
      },
      "source": [
        "## 4.1 Feature Extracter로 사전 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivyu6pyEL7_G"
      },
      "source": [
        "이미지넷으로 이미 학습된 가중치를 그대로 활용하기 위해서 Feature Extrator를 사용합니다. EfficientNetB0은 선, 모양 색 변화 등 저 수준의 특징을 추출하는 하위층과 귀,입, 꼬리 등 물체의 일부를 감지하는 중간 층, 그리고 전체 물체와 감정등을 추론하는 상위층으로 이루어져 있습니다.Feature Extractor에서 하위, 중간층만 그대로 받아옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JL88ZZip5nBk",
        "outputId": "01568921-4dd8-4152-9537-52f9fe100f4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
            "\u001b[1m258076736/258076736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n",
            "Epoch 1/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 763ms/step - accuracy: 0.2509 - loss: 1.7872 - val_accuracy: 0.2500 - val_loss: 1.4247 - learning_rate: 0.0010\n",
            "Epoch 2/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 645ms/step - accuracy: 0.2443 - loss: 1.6964 - val_accuracy: 0.2444 - val_loss: 1.5392 - learning_rate: 0.0010\n",
            "Epoch 3/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 638ms/step - accuracy: 0.2570 - loss: 1.6073 - val_accuracy: 0.2500 - val_loss: 1.4461 - learning_rate: 0.0010\n",
            "Epoch 4/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 635ms/step - accuracy: 0.2357 - loss: 1.6074 - val_accuracy: 0.2500 - val_loss: 1.5289 - learning_rate: 0.0010\n",
            "Epoch 5/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 635ms/step - accuracy: 0.2566 - loss: 1.5532 - val_accuracy: 0.2500 - val_loss: 1.4181 - learning_rate: 3.0000e-04\n",
            "Epoch 6/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 655ms/step - accuracy: 0.2397 - loss: 1.5525 - val_accuracy: 0.2500 - val_loss: 1.4144 - learning_rate: 3.0000e-04\n",
            "Epoch 7/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 637ms/step - accuracy: 0.2437 - loss: 1.5215 - val_accuracy: 0.2500 - val_loss: 1.4482 - learning_rate: 3.0000e-04\n",
            "Epoch 8/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 642ms/step - accuracy: 0.2495 - loss: 1.5232 - val_accuracy: 0.2472 - val_loss: 1.4077 - learning_rate: 3.0000e-04\n",
            "Epoch 9/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 646ms/step - accuracy: 0.2433 - loss: 1.5065 - val_accuracy: 0.2528 - val_loss: 1.4110 - learning_rate: 3.0000e-04\n",
            "Epoch 10/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 639ms/step - accuracy: 0.2499 - loss: 1.4870 - val_accuracy: 0.2500 - val_loss: 1.4495 - learning_rate: 3.0000e-04\n",
            "Epoch 11/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 641ms/step - accuracy: 0.2474 - loss: 1.4917 - val_accuracy: 0.2389 - val_loss: 1.3980 - learning_rate: 3.0000e-04\n",
            "Epoch 12/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 636ms/step - accuracy: 0.2270 - loss: 1.4999 - val_accuracy: 0.2500 - val_loss: 1.4052 - learning_rate: 3.0000e-04\n",
            "Epoch 13/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 637ms/step - accuracy: 0.2260 - loss: 1.5056 - val_accuracy: 0.2500 - val_loss: 1.4021 - learning_rate: 3.0000e-04\n",
            "Epoch 14/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 639ms/step - accuracy: 0.2519 - loss: 1.4769 - val_accuracy: 0.2500 - val_loss: 1.4321 - learning_rate: 3.0000e-04\n",
            "Epoch 15/15\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 645ms/step - accuracy: 0.2476 - loss: 1.4615 - val_accuracy: 0.2583 - val_loss: 1.3935 - learning_rate: 9.0000e-05\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB7\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.regularizers import l2  # L2 정규화 임포트\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3)\n",
        "\n",
        "base_model = EfficientNetB7(weights='imagenet', include_top=False, input_shape=(112, 112, 3))\n",
        "base_model.trainable = False  # 처음엔 학습하지 않음 (Feature Extractor로 사용)\n",
        "\n",
        "inputs = Input(shape=(112, 112, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.6)(x)\n",
        "outputs = Dense(len(class_names), activation='softmax', kernel_regularizer=l2(0.001))(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 1차 학습 (기본 모델 고정)\n",
        "hist = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=15,\n",
        "    validation_data=(val_images, val_labels),\n",
        "    #callbacks=[early_stop]\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZfWefwn7o5S"
      },
      "source": [
        "## 4.2 상위층 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TS7rYhmY7uRx"
      },
      "outputs": [],
      "source": [
        "# base_model의 일부 층부터 학습 가능하게 설정\n",
        "base_model.trainable = True\n",
        "\n",
        "# (선택) 특정 층까지만 학습되도록 설정하고 싶을 때:\n",
        "fine_tune_at = len(base_model.layers) - 20  # 맨 끝 20개만 학습 가능하게\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "   layer.trainable = False\n",
        "\n",
        "# 컴파일 다시 (학습 가능한 가중치가 생겼기 때문)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-4),  # 전이학습엔 낮은 학습률이 중요\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "#2차 학습 (전이 학습)\n",
        "# hist_fine = model.fit(\n",
        "#     train_images, train_labels,\n",
        "#     epochs=20,\n",
        "#     validation_data=(val_images, val_labels),\n",
        "#         callbacks=[early_stop, reduce_lr]\n",
        "# )\n",
        "# 2차 학습 (전이 학습, 데이터 증강 포함)\n",
        "# hist_fine = model.fit(\n",
        "#     train_generator,\n",
        "#     epochs=20,\n",
        "#     validation_data=(val_images, val_labels),\n",
        "#     callbacks=[early_stop, reduce_lr],\n",
        "#     #steps_per_epoch=len(train_images) // 32\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgVBy36tlyFk"
      },
      "source": [
        "# 5. 데이터 증강학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfMOgN66lIyh"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah1nikw-lKT7",
        "outputId": "c348721b-ee60-4da2-f5a1-7102d867dbe1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.2389 - loss: 1.4375 - val_accuracy: 0.2500 - val_loss: 1.3924 - learning_rate: 3.0000e-05\n",
            "Epoch 2/20\n",
            "\u001b[1m  1/101\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.2500 - loss: 1.4029"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2500 - loss: 1.4029 - val_accuracy: 0.2500 - val_loss: 1.3925 - learning_rate: 3.0000e-05\n",
            "Epoch 3/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - accuracy: 0.2424 - loss: 1.4123 - val_accuracy: 0.2500 - val_loss: 1.3958 - learning_rate: 3.0000e-05\n",
            "Epoch 4/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3125 - loss: 1.4259 - val_accuracy: 0.2500 - val_loss: 1.3957 - learning_rate: 3.0000e-05\n",
            "Epoch 5/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 103ms/step - accuracy: 0.2660 - loss: 1.4080 - val_accuracy: 0.2667 - val_loss: 1.3898 - learning_rate: 9.0000e-06\n",
            "Epoch 6/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1875 - loss: 1.4729 - val_accuracy: 0.2667 - val_loss: 1.3897 - learning_rate: 9.0000e-06\n",
            "Epoch 7/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 113ms/step - accuracy: 0.2642 - loss: 1.3995 - val_accuracy: 0.2528 - val_loss: 1.3866 - learning_rate: 9.0000e-06\n",
            "Epoch 8/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4375 - loss: 1.3534 - val_accuracy: 0.2528 - val_loss: 1.3866 - learning_rate: 9.0000e-06\n",
            "Epoch 9/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 112ms/step - accuracy: 0.2583 - loss: 1.4092 - val_accuracy: 0.2639 - val_loss: 1.3863 - learning_rate: 9.0000e-06\n",
            "Epoch 10/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4375 - loss: 1.3399 - val_accuracy: 0.2722 - val_loss: 1.3863 - learning_rate: 9.0000e-06\n",
            "Epoch 11/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 114ms/step - accuracy: 0.2540 - loss: 1.4035 - val_accuracy: 0.2639 - val_loss: 1.3851 - learning_rate: 9.0000e-06\n",
            "Epoch 12/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2812 - loss: 1.4063 - val_accuracy: 0.2667 - val_loss: 1.3851 - learning_rate: 9.0000e-06\n",
            "Epoch 13/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 112ms/step - accuracy: 0.2507 - loss: 1.4102 - val_accuracy: 0.2667 - val_loss: 1.3852 - learning_rate: 9.0000e-06\n",
            "Epoch 14/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1875 - loss: 1.4613 - val_accuracy: 0.2694 - val_loss: 1.3852 - learning_rate: 9.0000e-06\n",
            "Epoch 15/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - accuracy: 0.2378 - loss: 1.4107 - val_accuracy: 0.2667 - val_loss: 1.3851 - learning_rate: 2.7000e-06\n",
            "Epoch 16/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3438 - loss: 1.3466 - val_accuracy: 0.2667 - val_loss: 1.3851 - learning_rate: 2.7000e-06\n",
            "Epoch 17/20\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 104ms/step - accuracy: 0.2300 - loss: 1.4074 - val_accuracy: 0.2722 - val_loss: 1.3854 - learning_rate: 2.7000e-06\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 데이터 증강 설정\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,          # 회전 범위\n",
        "    width_shift_range=0.1,      # 가로 이동\n",
        "    height_shift_range=0.1,     # 세로 이동\n",
        "    shear_range=0.15,            # 전단 변형\n",
        "    zoom_range=0.2,             # 확대/축소\n",
        "    horizontal_flip=True,       # 좌우 반전\n",
        "    fill_mode='nearest'         # 빈 픽셀 채우는 방식\n",
        ")\n",
        "\n",
        "# 증강된 데이터로 학습\n",
        "train_generator = datagen.flow(train_images, train_labels, batch_size=32)\n",
        "\n",
        "# 모델 학습 (fit 대신 fit_generator 사용)\n",
        "hist_fine = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=(val_images, val_labels),\n",
        "    #callbacks=[early_stop],\n",
        "    callbacks=[early_stop, reduce_lr],\n",
        "    steps_per_epoch=len(train_images) // 32\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMjlRYRblLVN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHFgXlvllIxv"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhW3Llkrn7K4"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9ZG3SeclLhp"
      },
      "source": [
        "# 6.테스트셋 평가"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wagcRjXWlbEx"
      },
      "source": [
        "## 6.1 테스트셋 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxJW92MemjgX",
        "outputId": "1c02bcfd-d68a-43e9-a2d0-e6bc17bf440a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 573ms/step - accuracy: 0.2831 - loss: 1.3916\n",
            "Test Accuracy: 0.2800, Test Loss: 1.3925\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3BOdYQbml_Z"
      },
      "source": [
        "Keras 방식의 테스트 정확도 계산"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKl1qyX7W-2-",
        "outputId": "ee71dd99-d76b-4a92-c8fc-236b6bd39b0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "실행 시작: 2025-05-31 19:16:13\n",
            "테스트 정확도: 0.2800\n",
            "실행 종료: 2025-05-31 19:16:21\n",
            "총 실행 시간: 7.89초\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "start_time = time.time()\n",
        "start_dt = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"실행 시작: {start_dt}\")\n",
        "\n",
        "# 평가\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
        "print(f\"테스트 정확도: {test_acc:.4f}\")\n",
        "\n",
        "end_time = time.time()\n",
        "end_dt = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"실행 종료: {end_dt}\")\n",
        "print(f\"총 실행 시간: {end_time - start_time:.2f}초\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74Nu1y7sld6X"
      },
      "source": [
        "## 6.2 모델저장"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1yerXPApXEG"
      },
      "source": [
        "자신의 드라이브에 저장되는 것이므로 파일 저장후 공용드라이브로 옮겨주어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBCuQy6nlgFN",
        "outputId": "270f0eec-7e75-475f-b4a0-2759c07bfb97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "실행 시작: 2025-05-31 19:24:36\n",
            "✅ .keras 형식으로 저장됨: ./models\\puppySenseModel_2025-05-31.keras\n",
            "✅ .h5 형식으로 저장됨: ./models\\puppySenseModel_2025-05-31.h5\n",
            "실행 종료: 2025-05-31 19:24:36\n",
            "총 실행 시간: 0.03초\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "# 실행 시간 측정 시작\n",
        "start_time = time.time()\n",
        "start_dt = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"실행 시작: {start_dt}\")\n",
        "\n",
        "# 저장 디렉토리 설정\n",
        "model_dir = \"./models\"\n",
        "\n",
        "# 🔧 파일로 존재하는 경우 삭제\n",
        "if os.path.exists(model_dir) and not os.path.isdir(model_dir):\n",
        "    os.remove(model_dir)\n",
        "\n",
        "# 디렉토리 생성\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# 오늘 날짜\n",
        "today_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# 저장 경로들\n",
        "keras_path = os.path.join(model_dir, f\"puppySenseModel_{today_str}.keras\")\n",
        "h5_path = os.path.join(model_dir, f\"puppySenseModel_{today_str}.h5\")\n",
        "\n",
        "# ✅ 간단한 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape=(10,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# ✅ .keras 형식 저장\n",
        "model.save(keras_path)\n",
        "print(f\"✅ .keras 형식으로 저장됨: {keras_path}\")\n",
        "\n",
        "# ✅ .h5 형식 저장\n",
        "model.save(h5_path)\n",
        "print(f\"✅ .h5 형식으로 저장됨: {h5_path}\")\n",
        "\n",
        "\n",
        "\n",
        "# 실행 시간 측정 종료\n",
        "end_time = time.time()\n",
        "end_dt = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "print(f\"실행 종료: {end_dt}\")\n",
        "print(f\"총 실행 시간: {end_time - start_time:.2f}초\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa0mNh9AlqOt"
      },
      "source": [
        "## 6.3 시각화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "xxRc464CmwMY",
        "outputId": "ea2b1ad7-1d47-497f-cd95-66c1938fc021"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "File format not supported: filepath=./models. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(./models, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name).",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m class_names = [\u001b[33m'\u001b[39m\u001b[33mangry\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhappy\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrelaxed\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msad\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# 1. 모델 로드\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m model = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./models\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 2. 데이터셋 로딩 (예시)\u001b[39;00m\n\u001b[32m     12\u001b[39m test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n\u001b[32m     13\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtest_path/\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     14\u001b[39m     image_size=(\u001b[32m112\u001b[39m, \u001b[32m112\u001b[39m),\n\u001b[32m     15\u001b[39m     batch_size=\u001b[32m32\u001b[39m\n\u001b[32m     16\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oculo\\Desktop\\test\\artificialin\\.conda\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:206\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    207\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mlegacy H5 format files (`.h5` extension). \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    210\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNote that the legacy SavedModel format is not \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    211\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupported by `load_model()` in Keras 3. In \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    212\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33morder to reload a TensorFlow SavedModel as an \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    213\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minference-only layer in Keras 3, use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    214\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`keras.layers.TFSMLayer(\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    215\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, call_endpoint=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mserving_default\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    216\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(note that your `call_endpoint` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmight have a different name).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    218\u001b[39m     )\n",
            "\u001b[31mValueError\u001b[39m: File format not supported: filepath=./models. Keras 3 only supports V3 `.keras` files and legacy H5 format files (`.h5` extension). Note that the legacy SavedModel format is not supported by `load_model()` in Keras 3. In order to reload a TensorFlow SavedModel as an inference-only layer in Keras 3, use `keras.layers.TFSMLayer(./models, call_endpoint='serving_default')` (note that your `call_endpoint` might have a different name)."
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 클래스 이름\n",
        "class_names = ['angry', 'happy', 'relaxed', 'sad']\n",
        "\n",
        "# 1. 모델 로드\n",
        "model = tf.keras.models.load_model('./models')\n",
        "\n",
        "# 2. 데이터셋 로딩 (예시)\n",
        "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'test_path/',\n",
        "    image_size=(112, 112),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# 3. 전체 이미지, 라벨을 numpy 배열로 변환\n",
        "test_images = []\n",
        "test_labels = []\n",
        "for images, labels in test_dataset:\n",
        "    test_images.append(images.numpy())\n",
        "    test_labels.append(labels.numpy())\n",
        "\n",
        "test_images = np.concatenate(test_images, axis=0)\n",
        "test_labels = np.concatenate(test_labels, axis=0)\n",
        "\n",
        "# One-hot encoding 된 라벨인 경우\n",
        "if test_labels.ndim == 2 and test_labels.shape[1] > 1:\n",
        "    y_true_class = np.argmax(test_labels, axis=1)\n",
        "else:\n",
        "    y_true_class = test_labels  # 정수형 라벨\n",
        "\n",
        "# 4. 예측\n",
        "y_pred = model.predict(test_images)\n",
        "y_pred_class = np.argmax(y_pred, axis=1)\n",
        "\n",
        "# 5. 시각화\n",
        "fig = plt.figure(figsize=(15, 10))\n",
        "for j in range(10):\n",
        "    ax = fig.add_subplot(2, 5, j + 1)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.imshow(test_images[j].astype(\"uint8\"))  # 정규화 해제 필요시 수정\n",
        "\n",
        "    true_label = class_names[y_true_class[j]]\n",
        "\n",
        "    prob_text = \"\\n\".join([\n",
        "        f\"{class_names[i]}: {y_pred[j][i]*100:.1f}%\" for i in range(len(class_names))\n",
        "    ])\n",
        "\n",
        "    ax.text(\n",
        "        0.5, -0.25,\n",
        "        f\"GT: {true_label}\\n{prob_text}\",\n",
        "        size=12,\n",
        "        ha='center',\n",
        "        va='center',\n",
        "        transform=ax.transAxes\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "-InunoyBp2Ul",
        "outputId": "589394ce-ae39-4c0e-d043-7775e53b4e9e"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'hist_fine' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 두 히스토리 합치기 (간단히 리스트 이어붙이기)\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# for key in hist_fine.history.keys():\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#     hist.history[key].extend(hist_fine.history[key])\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m common_keys = \u001b[38;5;28mset\u001b[39m(hist.history.keys()).intersection(\u001b[43mhist_fine\u001b[49m.history.keys())\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m common_keys:\n\u001b[32m      6\u001b[39m     hist.history[key].extend(hist_fine.history[key])\n",
            "\u001b[31mNameError\u001b[39m: name 'hist_fine' is not defined"
          ]
        }
      ],
      "source": [
        "# 두 히스토리 합치기 (간단히 리스트 이어붙이기)\n",
        "# for key in hist_fine.history.keys():\n",
        "#     hist.history[key].extend(hist_fine.history[key])\n",
        "common_keys = set(hist.history.keys()).intersection(hist_fine.history.keys())\n",
        "for key in common_keys:\n",
        "    hist.history[key].extend(hist_fine.history[key])\n",
        "\n",
        "# 이제 hist.history에 10 epoch의 기록이 모두 들어있음\n",
        "\n",
        "# 에포크 수 및 히스토리 정보\n",
        "epochs = len(hist.history['loss'])  # epochs 수를 자동으로 가져옵니다\n",
        "train_loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        "train_acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "xc = range(epochs)\n",
        "\n",
        "# 손실 그래프\n",
        "plt.figure(1, figsize=(7, 5))\n",
        "plt.plot(xc, train_loss, label='train')\n",
        "plt.plot(xc, val_loss, label='val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.style.use(['classic'])\n",
        "\n",
        "# 정확도 그래프\n",
        "plt.figure(2, figsize=(7, 5))\n",
        "plt.plot(xc, train_acc, label='train')\n",
        "plt.plot(xc, val_acc, label='val')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend(loc='lower right')\n",
        "plt.style.use(['classic'])\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "s5OkvRWnlsL_",
        "outputId": "6d3b9435-e8a7-49df-8499-632197922caf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.24      0.06      0.10       100\n",
            "       happy       0.27      0.22      0.24       100\n",
            "     relaxed       0.25      0.74      0.38       100\n",
            "         sad       0.67      0.02      0.04       100\n",
            "\n",
            "    accuracy                           0.26       400\n",
            "   macro avg       0.36      0.26      0.19       400\n",
            "weighted avg       0.36      0.26      0.19       400\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x640 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(test_images)\n",
        "y_pred_labels = np.argmax(y_pred, axis=1)\n",
        "y_true_labels = np.argmax(test_labels, axis=1)\n",
        "\n",
        "print(classification_report(y_true_labels, y_pred_labels, target_names=class_names))\n",
        "\n",
        "# 혼동 행렬 시각화\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuY04qYjlqN2"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
