# -*- coding: utf-8 -*-
"""PuppySense.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T_NWOdyZ5qdcaHP2xCpeKc5uYxdgykh9

# PuppySense

인공지능응용 프로젝트

모델학습 (colab 환경설정, 전이 학습 설정 진행)

## 1. Colab 환경설정 (GPU + 라이브러리 설치)
"""

!pip install tensorflow opencv-python matplotlib
!pip install efficientnet

"""# 2. 데이터 전처리하기

## 2.1 kaggle 데이터 다운하기
"""

import os
import pandas as pd
import numpy as np
import tensorflow as tf
import cv2
import kagglehub

# 1. kagglehub로 실제 경로 다운로드
path = kagglehub.dataset_download("danielshanbalico/dog-emotion")
data_dir = os.path.join(path, 'Dog Emotion')
print("실제 다운로드된 경로:", path)
print("해당 경로 내 파일/폴더:", os.listdir(path))

"""## 2.2 데이터 로드

"""

# 2. labels.csv 경로
labels_csv_path = os.path.join(data_dir, 'labels.csv')
labels_df = pd.read_csv(labels_csv_path)

# 3. 감정 레이블 폴더 이름 불러오기
class_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])
print(f'클래스 목록: {class_names}')

# 4. 레이블 매핑
label_map = {name: idx for idx, name in enumerate(class_names)}

# 5. 이미지 로딩 함수
def load_and_preprocess_img(img_path):
    img = cv2.imread(img_path)
    if img is None:
        print(f"이미지 파일을 불러올 수 없습니다: {img_path}")
        return None
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (112, 112))
    img = img / 255.0
    return img

# 6. 이미지 및 레이블 로딩
images, labels = [], []
for _, row in labels_df.iterrows():
    img_path = os.path.join(data_dir, row['label'], row['filename'])
    img = load_and_preprocess_img(img_path)
    if img is not None:
        images.append(img)
        labels.append(label_map[row['label']])

# 7. 배열 및 one-hot 인코딩
images = np.array(images)
labels = tf.keras.utils.to_categorical(labels, num_classes=len(class_names))

# 8. 확인
print(f'이미지 개수: {images.shape[0]}, 라벨 개수: {labels.shape[0]}')
print(f'라벨 예시 (one-hot):\n{labels[:5]}')

"""# 3. test, valid, train set 나누기"""

from sklearn.model_selection import train_test_split

# 1) train+val / test 분리 (10%를 test로 분리)
train_val_images, test_images, train_val_labels, test_labels = train_test_split(
    images, labels, test_size=0.1, random_state=42, stratify=labels
)

# 2) train / val 분리 (train_val 중 10%를 validation으로 분리)
train_images, val_images, train_labels, val_labels = train_test_split(
    train_val_images, train_val_labels, test_size=0.1, random_state=42, stratify=train_val_labels
)

"""# 4. 전이 학습 모델 구성 (EfficientNetB0 사용)

## 4.1 Feature Extracter로 사전 학습

이미지넷으로 이미 학습된 가중치를 그대로 활용하기 위해서 Feature Extrator를 사용합니다. EfficientNetB0은 선, 모양 색 변화 등 저 수준의 특징을 추출하는 하위층과 귀,입, 꼬리 등 물체의 일부를 감지하는 중간 층, 그리고 전체 물체와 감정등을 추론하는 상위층으로 이루어져 있습니다.Feature Extractor에서 하위, 중간층만 그대로 받아옵니다.
"""

from tensorflow.keras.applications import EfficientNetB4
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.regularizers import l2  # ✅ L2 정규화 임포트

early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3)

base_model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(112, 112, 3))
base_model.trainable = False  # 처음엔 학습하지 않음 (Feature Extractor로 사용)

inputs = Input(shape=(112, 112, 3))
x = base_model(inputs, training=False)
x = GlobalAveragePooling2D()(x)
x = Dropout(0.6)(x)

outputs = Dense(len(class_names), activation='softmax', kernel_regularizer=l2(0.0001))(x)

model = Model(inputs, outputs)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# 1차 학습 (기본 모델 고정)
hist = model.fit(
    train_images, train_labels,
    epochs=15,
    validation_data=(val_images, val_labels),
    callbacks=[early_stop, reduce_lr]
)

"""## 4.2 상위층 학습"""

# base_model의 일부 층부터 학습 가능하게 설정
base_model.trainable = True

# (선택) 특정 층까지만 학습되도록 설정하고 싶을 때:
# fine_tune_at = 100
# for layer in base_model.layers[:fine_tune_at]:
#     layer.trainable = False

# 컴파일 다시 (학습 가능한 가중치가 생겼기 때문)
model.compile(
    optimizer=tf.keras.optimizers.Adam(1e-5),  # 전이학습엔 낮은 학습률이 중요
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# 2차 학습 (전이 학습)
hist_fine = model.fit(
    train_images, train_labels,
    epochs=20,
    validation_data=(val_images, val_labels),
        callbacks=[early_stop, reduce_lr]
)

"""# 5. 데이터 증강학습"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=20,          # 회전
    width_shift_range=0.1,      # 가로 이동
    height_shift_range=0.1,     # 세로 이동
    shear_range=0.1,            # 전단
    zoom_range=0.2,             # 확대/축소
    horizontal_flip=True,       # 좌우 반전
    fill_mode='nearest'         # 빈 영역 보정 방식
)

train_generator = datagen.flow(train_images, train_labels, batch_size=8)

hist = model.fit(
    train_generator,
    epochs=15,
    validation_data=(val_images, val_labels),
    callbacks=[early_stop, reduce_lr],
    steps_per_epoch=len(train_images) // 8  # 증강은 batch 기반이라 꼭 필요함
)



"""# 6.테스트셋 평가

## 6.1 테스트셋 평가
"""

test_loss, test_acc = model.evaluate(test_images, test_labels)
print(f"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}")

"""Keras 방식의 테스트 정확도 계산"""

import time
from datetime import datetime

start_time = time.time()
start_dt = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
print(f"실행 시작: {start_dt}")

# 평가
test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)
print(f"테스트 정확도: {test_acc:.4f}")

end_time = time.time()
end_dt = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
print(f"실행 종료: {end_dt}")
print(f"총 실행 시간: {end_time - start_time:.2f}초")

"""## 6.2 모델저장

자신의 드라이브에 저장되는 것이므로 파일 저장후 공용드라이브로 옮겨주어야 합니다.
"""

import os
import time
from datetime import datetime
from google.colab import drive

# Google Drive 마운트
drive.mount('/content/drive')

# 실행 시간 측정 시작
start_time = time.time()
start_dt = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
print(f"실행 시작: {start_dt}")

# 저장 디렉토리 설정
model_dir = "/content/drive/MyDrive/models"
os.makedirs(model_dir, exist_ok=True)

# 오늘 날짜를 파일 이름에 포함 (예: puppySenseModel_2025-05-23.keras)
today_str = datetime.now().strftime("%Y-%m-%d")
model_filename = f"puppySenseModel_{today_str}.keras"
model_path = os.path.join(model_dir, model_filename)

# 모델 저장 (TensorFlow/Keras)
model.save(model_path)
print(f"✅ 모델이 저장되었습니다: {model_path}")

# 실행 시간 측정 종료
end_time = time.time()
end_dt = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
print(f"실행 종료: {end_dt}")
print(f"총 실행 시간: {end_time - start_time:.2f}초")

#tensorFlow Model로 저장
model.save('saved_model/emotion_model')

"""## 6.3 시각화"""

import matplotlib.pyplot as plt
import numpy as np

# 클래스 이름
class_names = ['angry', 'happy', 'relaxed', 'sad']

# 예측 확률
y_pred = model.predict(test_images)  # shape: (4000, 4)

# 예측 클래스 (argmax)
y_pred_class = np.argmax(y_pred, axis=1)
y_true_class = np.argmax(test_labels, axis=1)

# 이미지 10개 출력
fig = plt.figure(figsize=(15, 10))
for j in range(10):
    ax = fig.add_subplot(2, 5, j + 1)
    ax.set_xticks([])
    ax.set_yticks([])
    ax.imshow(test_images[j])  # 정규화된 이미지면 되돌리기

    true_label = class_names[y_true_class[j]]

    # 확률 리스트 문자열 생성
    prob_text = "\n".join([
        f"{class_names[i]}: {y_pred[j][i]*100:.1f}%" for i in range(len(class_names))
    ])

    # 텍스트 출력
    ax.text(
        0.5, -0.25,
        f"GT: {true_label}\n{prob_text}",
        size=12,
        ha='center',
        va='center',
        transform=ax.transAxes
    )

plt.tight_layout()
plt.show()

# 두 히스토리 합치기 (간단히 리스트 이어붙이기)
for key in hist_fine.history.keys():
    hist.history[key].extend(hist_fine.history[key])

# 이제 hist.history에 10 epoch의 기록이 모두 들어있음

# 에포크 수 및 히스토리 정보
epochs = len(hist.history['loss'])  # epochs 수를 자동으로 가져옵니다
train_loss = hist.history['loss']
val_loss = hist.history['val_loss']
train_acc = hist.history['accuracy']
val_acc = hist.history['val_accuracy']
xc = range(epochs)

# 손실 그래프
plt.figure(1, figsize=(7, 5))
plt.plot(xc, train_loss, label='train')
plt.plot(xc, val_loss, label='val')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training vs Validation Loss')
plt.grid(True)
plt.legend()
plt.style.use(['classic'])

# 정확도 그래프
plt.figure(2, figsize=(7, 5))
plt.plot(xc, train_acc, label='train')
plt.plot(xc, val_acc, label='val')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training vs Validation Accuracy')
plt.grid(True)
plt.legend(loc='lower right')
plt.style.use(['classic'])

plt.show()

from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

y_pred = model.predict(test_images)
y_pred_labels = np.argmax(y_pred, axis=1)
y_true_labels = np.argmax(test_labels, axis=1)

print(classification_report(y_true_labels, y_pred_labels, target_names=class_names))

# 혼동 행렬 시각화
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_true_labels, y_pred_labels)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names, cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()